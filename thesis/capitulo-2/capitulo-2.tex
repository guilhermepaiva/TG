\chapter{Combinação de Classificadores}

Neste capítulo, será mostrado um conceito e análise de combinação de classificadores e os principais algoritmos desta área, Bagging e Boosting. Cada seção aborda os conceitos básicos do tema e de cada algoritmo, o seu pseudo-código e suas características principais, bem como as variações mais conhecidas. Ao final, de maneira mais detalhada, será analisado o algoritmo ICS-Bagging com foco nas possíveis métricas de diversidade que este algoritmo pode usar bem como uma análise a respeito de métricas de diversidade. 

\section{Selecionar Classificadores}

Antes de se combinar classificadores de fato é preciso selecioná-los. Em uma análise menos acurada, parece ser algo intuitivo. No entanto, neste assunto reside alguns aspectos importantes que servem de base para o entendimento dos algoritmos que serão tratados nas próximas seções. 
A ideia base de se selecionar classificadores é de que existe uma espécie de "oráculo" que pode selecionar o melhor classificador para uma dada entrada \textbf{x}. A decisão deste melhor classificador é tida como sendo a decisão do conjunto de classificadores. 
A ideia de usar diferentes classificadores para diferentes entradas foi primeiramente sugerida por Dasarathy e Sheela em 1978 [ref 118]. Os autores combinaram um classificador linear e o \textit{K-Nearest Neighbor}. A combinação dos classificadores identifica o domínio de conflito dentro do espaço de características e utiliza o \textit{K-Nearest Neighbor} neste domínio, enquanto que o classificador linear é utilizado nos demais domínios. E no ano de 1981 Rastrigin e Erenstein [ref 119] propuseram uma metodologia de seleção de classificadores como é conhecida atualmente. 
Posteriormente, o interesse em seleção de classificadores foi impulsionado pela publicação de Woods et al. [ref 120]. Os autores introduziram o termo \textit{seleção dinâmica de classificadores} para denotar o processo de escolher um membro do conjunto de classificadores para tomar uma decisão baseada na entrada \textbf{x}.
Partindo desta proposta, para se construir a seleção do conjunto de classificadores, algumas perguntas precisam ser feitas:
\begin{itemize} \item Como construir os classificadores individuais? \item Como avaliar a competência de cada classificador dado uma entrada \textbf{x}? \item Uma vez que a competência de um classificador foi avaliada, qual estratégia deverá ser utilizada?  \end{itemize}

\subsection{Regras de Combinação} 

Como será visto adiante, alguns algoritmos de combinação de classificadores possuem regras de combinação embutidas no seu próprio algoritmo. Por exemplo, o algoritmo Bagging utiliza uma maioria dos votos simples, já no AdaBoost é utilizado uma maioria dos votos com pesos. No entanto, um conjunto de classificadores pode ser treinado simplesmente usando um subconjunto do conjunto de treinamento, diferentes parâmetros dos classificadores ou até mesmo diferentes subconjuntos de características. 

Os classificadores podem ser combinados usando uma ou mais regras de combinação. Algumas dessas regras de combinação operam apenas nos \textit{labels} das classes, outras possuem mecanismos mais sofisticados. Mas, de forma prática, pode-se dividir as regras de combinação entre métodos baseados em votos, métodos algébricos e outras formas de combinação. 

A regra baseada em votos, é bastante simples, e como o próprio nome já diz, cada classificador dá um voto ao classificar uma nova instância. Duas formas de votos são muito conhecidas, o voto da maioria e o voto com pesos. No primeiro caso, cada classificador, ao receber uma nova instância a ser classificada, provê seu voto como sendo o resultado da sua classificação. A classe que foi apontada como a maioria dos votos é a classe na qual a instância será classificada. Analogamente, nos votos com pesos, alguns classificadores ou até mesmo instância de treinamento, possuem um peso maior. De forma que a votação se dá da mesma forma, apenas algumas instâncias ou classificadores detêm um peso maior no seu voto.

Outras regras são conhecidas na literatura, porém não é o objetivo de estudo deste trabalho. Estes incluem \textit{Borda count},\textit{behavior knowledge space} e \textit{decision templates} como rol apenas exemplificativo, já que a lista não se exaure dentro destes. 

\subsection{Diversidade}

O sucesso de um sistema que combina classificadores reside na diversidade dos seus membros. De forma que se todos os classificadores fornecessem a mesma saída, nada estaria sendo feito, e nenhum erro poderia ser corrigido. Por isso cada classificador individual precisa de diferente, de certa forma, dos demais classificadores. Isso leva ao raciocínio de que erros cometidos por alguns classificadores são compensados por acertos dos outros classificadores, assim obtêm-se uma diminuição do erro global. Outra forma de se obter ganho nessa abordagem, é que alguns classificadores são bons em determinados domínios do problemas, e a diversidade destes classificadores faz com que uma maior região do problema possa ser resolvida de uma forma maior acurada.  

\subsection{Pontos Fracos}

A contrapartida do aumento da taxa de acerto ao se combinar classificadores ocorre um principalmente três pontos: é necessário mais armazenamento, mais capacidade computacional e a complexidade de entendimento aumenta. O primeiro ponto fraco, necessidade de mais armazenamento, é consequência direta de que vários classificadores e não apenas um precisa ser armazenado após a fase de treinamento. O segundo problema decorre naturalmente do aumento da capacidade computacional requerida dado que vários classificadores precisam ser processados e não apenas um. O último, complexidade no entendimento, envolve uma maior dificuldade para se compreender de forma intuitiva ou até mesmo trivial o que realmente incorpora melhores resultados nos algoritmos.

\section{Bagging}

\subsection{Origem do Algoritmo Bagging}

\textit{Bagging} é um algoritmo \cite{bagging:1996} de combinação de classificadores que foi desenvolvido com o intuito de melhorar a acurácia na tarefa de classificação. O principal conceito deste algoritmo é o \textit{Bootstrap AGGregatING}, na qual o conjunto de treinamento para cada classificador é construído a partir de uma amostra escolhida aleatoriamente do conjunto de treinamento. Os classificadores são então combinados e ao se apresentar uma nova instância, cada classificador fornece como resultado a classe na qual essa nova instância pertence. Normalmente, a classe que obteve mais votos, é dita como sendo a classe desta instância. 
A diversidade necessária para fazer com que o conjunto funcione é obtida pelo fato de se utilizar diferentes conjuntos de treinamento. Idealmente, os conjuntos de treinamento devem ser criados randomicamente do conjunto de treinamento. E abaixo o algoritmo pode ser entendido, de forma que pode ser notado que este é um algoritmo paralelo nas fases de treinamento e operacional. 


\begin{algorithm}
\caption{Bagging}
\label{alg:bagging}
\begin{algorithmic}
\STATE Dado o conjunto de treinamento $T$
\FORALL {t = 1, ..., n}
		\STATE Para cada amostra $S$ do conjunto de treinamento $T$ selecione \textit{m} exemplos aleatórios com reposição
		\STATE Considere $ht$ o resultado do classificador $t$ para o conjunto de treinamento $S$
\ENDFOR
\STATE $Resultado \gets$ a maioria dos votos de $(h1(x), ..., hT(x))$
\RETURN $Resultado$
\end{algorithmic}
\end{algorithm}

Assim, como pode ser observado melhor acima, para cada \textit{n} interações uma réplica do conjunto de treinamento é criada. E um classificador é treinado com essa réplica, este processo continua até uma quantidade de interações desejada. Após uma quantidade de interações previamente escolhida, uma combinação de classificadores é gerada e a maioria dos votos desses classificadores determina a classe de uma nova instância. A figura \ref{fig:bagging} ilustra o funcionamento do algoritmo.

\begin{figure}[H]
\center
\includegraphics[scale=0.45]{imagens/bagging.png}
\caption{Bagging}
\label{fig:bagging}
\end{figure}

\subsection{A Razão do Bagging Funcionar}

Se as saídas dos classificadores fossem independentes e os classificadores tivessem a mesma acurácia \textit{p}, então a maioria do votos simples dos classificadores já garante um ganho com relação a um único classificador. O algoritmo Bagging tem como objetivo treinar classificadores independentes utilizando réplicas de amostras da base de treinamento. Estas réplicas são pseudo-independentes pelo fato de terem sido obtidas do mesmo conjunto de treinamento. No entanto, este fato não anula o fato das respostas dos classificadores individuais serem independentes. 

\subsection{Variantes do Algoritmo Bagging}

As seções abaixo mostra algumas variantes do algoritmo têxtil{bagging}, bem como o seu funcionamento e definição.

\subsubsection{Random Forest}

Breiman propôs uma variante do algoritmo têxtil{bagging} [214] que o chamou de \textit{random forest}. Este algoritmo é uma classe geral para os métodos de combinação de classificadores que utilizam uma árvore de decisão como classificador base. Para ser rotulado como um "\textit{random forest}" um conjunto de árvores de decisão deve ser construído gerando vetores aleatórios independentes e distribuídos de maneira idêntica, e utilizar cada vetor para crescer a árvore de decisão. Uma definição formal pode ser obtida abaixo.

\textbf{Definição: } \textit{Random Forest} é um classificador consistindo de uma coleção de classificadores do tipo árvore de decisão. Cada árvore de decisão cresce respeitando um vetor aleatório onde cada elemento deste vetor é independente e identicamente distribuído. Cada árvore de decisão provê um único voto dado um entrada \textbf{x} e o resultado é a saída \textbf{y} que é a maioria simples dos votos. A figura \ref{fig:randomforest} ilustra a definição.

\begin{figure}[H]
\center
\includegraphics[scale=0.80]{imagens/randomforest.png}
\caption{Random Forest}
\label{fig:randomforest}
\end{figure}

\subsubsection{Pasting Small Votes}

Bases de dados grandes são mais comuns atualmente do que no início do desenvolvimento dos primeiros algoritmos de combinação de classificadores. E a disponibilidade de aumento de capacidade computacional permitiu com que a manipulação dessa massa maior de dados disponível fosse possível. Breiam [215] então sugeriu o que ficou conhecido como \textit{small votes}, na qual classificadores individuais são treinados com pequenos subconjuntos do conjunto de treinamento. Os conjuntos de treinamento são obtidos de forma aleatória do conjunto original. Caso esse conjunto seja obtido de forma similar ao \textit{bagging} então este é denominado \textit{RVotes}, e caso seja baseado em importância, é denominado de \textit{IVotes}.\textit{Pasting Small Votes} é adequado para aprendizado \textit{on-line}, de forma que o conjunto de classificadores pode ser atualizado adicionando um novo classificador cada vez que uma nova quantidade de dados do conjunto de treinamento é acumulada. \textit{Pasting RVotes} possui o como ponto positivo o fato de ser mais simples, no entendo perde em acurácia se comparado com \textit{Pasting IVotes} [215, 216].

\begin{algorithm}[h]
\caption{IVotes}
\label{alg:ivotes}
\begin{algorithmic}[1]
\STATE \textbf{ENTRADA:} Conjunto de Treinamento: $S$, Número de Iterações: $T$, Tamanho do Bootstrap: $n$,  Classificador fraco: $I$.
\STATE {\textbf{SAÍDA:} O Classificador Final: $H(x) = sign\left(\sum_{t=1}^T h_t(x) \right)$ onde $h_t(x))$ onde $h_t(x)  \in \{-1, +1\}$.}
\item $e_n \gets$ 0.5
\item \textbf{Repita}
\item  {$e_o \gets e_n$}
\item  {$S_t \gets \emptyset$}
\WHILE{\textit{size} $S_t$ < \textit{n}} 
\STATE{$x \gets InstanciaAleatoria(S)$} 
\IF{$x$ for classificado de forma incorreta por um classificador fora do conjunto} 
\STATE{$S_t \gets S_t \cup \{x\}$} 
\ELSE 
\STATE{$S_t \gets S_t \cup \{x\}$ com probabilidade $(\frac{e_o}{1- e_o})$} 
\ENDIF
\ENDWHILE
\item $h_t \gets I(S_t)$
\item $e_n \gets$ erro do classificador fora do conjunto
\item \textbf{Até} $e_n < e_o$

\end{algorithmic}
\end{algorithm}

\subsubsection{Random Subspace}

O método \textit{Random Subspace} \ref{tk:1998} consiste em utilizar vários classificadores cada um operando em um subespaço do espaço de características. De forma mais específica, o classificador consiste em se construir sistematicamente múltiplas árvores selecionando pseudorandomicamente subconjuntos dos componentes do vetor de características. Dessa formas, as árvores são construídas por esses subespaços escolhidos randomicamente.
Este método, como já detalhado anteriormente, utiliza um subconjunto de características selecionadas aleatoriamente e atribui a um determinado algoritmo de aprendizagem. Dessa forma, é obtido um subespaço aleatório do espaço de características original, construindo assim os classificadores dentro desse espaço reduzido. 
A forma mais comum utilizada para se obter o resultado é por meio de um voto de cada classificador utilizando-se pesos. Isso se justifica por ter sido mostrado que este método é eficiente para classificadores que possuem um curva de aprendizado decrescente construída sobre um conjunto pequeno de treinamento.
O conjunto de classificadores é construído como pode ser visto no algoritmo abaixo:

\begin{algorithm}[h]
\caption{Random Subspace}
\label{alg:randomsubspace}
\begin{enumerate}
\item Considere um número de objetos de treinamento $N$ e o número de características do conjunto de dados como sendo $D$.
\item Atribua $L$ como sendo o número de classificadores do conjunto de classificadores.
\item Para cada classificador individual $I$, escolha $d_i$ ($d_i$ < $D$) como sendo o número de variáveis de entrada para $I$.
\item Para cada classificador individual $I$, crie um conjunto de treinamento escolhendo $d_i$ características de $D$ sem reposição e treine o classificador.
\item Para classificar um novo objeto, combine as saídas de cada classificador individual $L$ utilizando a maioria dos votos com pesos.
\end{enumerate}

\end{algorithm}



\section{Boosting}

\subsection{Origem do Algoritmo Boosting}

Podemos dizer que \textit{Boosting} é um método geral para melhorar a precisão de uma classificação[219]. Este algoritmo foi desenvolvido por Schapire em 1990 [40 review] e o objetivo deste método é produzir um classificador forte a partir de um conjunto de vários classificadores fracos. Um classificador é dito fraco quando este tem uma taxa de acerto boa, mas somente para uma porção da base de dados. Por isso a ideia de combinar vários classificadores ditos fracos para formar uma combinação de classificadores que tem uma precisão melhor. Um analogia favorável ao entendimento é que um classificador fraco é um bom classificador para um determinado domínio, e a junção de vários classificadores fracos forma uma combinação de classificadores forte.

O método \textit{boosting} treina iterativamente cada classificador atribuindo a cada instância um peso após este treinamento. Os pesos de cada instância são acrescidos quando esta instância é classificada incorretamente e analogamente este peso é decrementado quando classificado corretamente. Isto faz com que cada classificador foque nos exemplos mais difíceis. Depois que a cominação de classificadores for gerada, uma regra de escolha é usada,  maioria dos votos por exemplo. 

\subsection{A Razão do Boosting Funcionar}

Um ponto bastante positivo desta família de algoritmos é sua convergência rápida da taxa de erro do conjunto de treinamento para valores ditos como bons, praticamente nas primeiras iterações. O meio usado para criar as bases de dados consiste em usar uma distribuição balanceada de instâncias fáceis e instâncias difíceis [42 review]. As instâncias difíceis são detectadas pelos classificadores fora do conjunto. Uma instância é considerada difícil quando é classificada de forma incorreta pelo conjunto de classificadores formado por aqueles classificadores que não usaram esta instância no seu treinamento.

\subsection{Variantes do Algoritmo Boosting}

As seções abaixo mostra algumas variantes do algoritmo têxtil{boosting}, bem como o seu funcionamento e definição.

\subsubsection{AdaBoost}
Um dos mais famosos algoritmos da família \textit{boosting} é o \textit{AdaBoost}, este algoritmo foi a primeira abordagem prática do \textit{Boosting} e hoje é apontando como um dos top dez dos algoritmos de aprendizagem de máquina[94 review] . Este algoritmo utiliza todo o conjunto de dados para treinar cada classificador, mas a cada iteração é dado um foco maior a instâncias difíceis de classificar. O objetivo é classificar corretamente na próxima iteração uma instância que foi classificada de forma errada na iteração atual. Com isso, é dado um foco maior em instâncias que são difíceis de se classificar.
Depois de cada iteração, os pesos das instâncias que foram classificadas de forma errada são aumentando; e em contraste, os pesos das instâncias que foram classificadas corretamente são decrementados. Além disso outro peso é atribuído a cada classificador individual, dependendo da sua taxa de acerto na fase de treinamento.
Finalmente, quando uma nova instância é apresentada, cada classificador dá um voto, e a classe selecionada foi a que obteve a maioria dos votos. Lembrando que os classificadores possuem pesos diferentes nas votações. O algoritmo pode ser conferido abaixo.

\begin{algorithm}[h]
\caption{AdaBoost}
\label{alg:adaboost}
\begin{algorithmic}[1]
\STATE \textbf{ENTRADA:}
\item Conjunto de Treinamento: $\mathcal{D} = \{(x_i, y_i), i=1, \ldots, N
\}$, onde $x_i \in \mathbf{R}^d$ e $y_i \in \{-1, +1\}$.
\item O número de amostras em cada iteração: $m$
\item Classificador Fraco: $\mathcal{L}$ que automaticamente aprende um classificador binário $h(x): \mathbf{R}^d \mapsto \{-1, +1\}$
de um conjunto de treinamento.
\item O número de iterações: $T$
\STATE \textbf{SAÍDA:}
\item O Classificador Final: $H(x) = sign\left(\sum_{t=1}^T \alpha_t h_t(x) \right)$

\STATE \textbf{Algoritmo}

\STATE Inicialize a distribuição $D_0(i) = 1/N, i=1, \ldots, N$

\FOR{$t = 1$ até $T$}

\STATE Escolha $m$ exemplos com reposição de $\mathcal{D}$
de acordo com a distribuição $D_{t-1}(i)$.

\STATE Treine o classificador $h_t(x)$ usando os exemplos da amostra

\STATE Compute a taxa de erro $\varepsilon_t = \sum_{i=1}^N
D_{t-1}(i) I(h_t(x_i) \neq y_i)$ onde $I(z)$ dá como saída $1$ quando $z$
é verdadeiro e zero caso contrário.

\STATE Saia do laço se $\varepsilon > 0.5$.

\STATE Compute o peso como $\alpha_t$ em
\[\alpha_t = \frac{1}{2}\ln\left(\frac{1-\varepsilon_t}{\varepsilon_t}\right) \]

\STATE Atualize a distribuição em as
\[ D_t(i) = \frac{1}{Z_t} D_{t-1}(i)\exp(\alpha_tI(y_i \neq h_t(x_i))\]
onde $Z_t = \sum_{i=1}^N D_{t-1}(i)\exp(\alpha_tI(y_i \neq
h_t(x_i))$.

\ENDFOR

\STATE Construa o classificador final $H(x) = sign(\sum_{t=1}^T
\alpha_t h_t(x))$.

\end{algorithmic}
\end{algorithm}

\subsubsection{AdaBoost.M1}

\subsubsection{AdaBoost.M2}

\section{Qual a melhor abordagem: \textit{Bagging} ou \textit{Boosting}}

Em princípio este tipo de pergunta se apresenta de forma mal colocada partindo do pressuposto que não existe o melhor método para todos os casos. No entanto, vários autores têm comparado as duas abordagens e gerando vários resultados [106, 116, 236, 238, 239 livro].  O consenso geral é de que os métodos \textit{boosting} alcançam uma menor taxa de erro. No entanto, algoritmos baseados em \textit{boosting} são sensíveis a ruídos e \textit{outliers}, especialmente quando a base de dados é pequena [116,236,239]. 

\section{ICS-Bagging}
O algoritmo ICS-Bagging,  acrônimo de \textit{Iteractive Classifier Selection Baggin},  é o ponto central e objetivo de estudo deste trabalho. Por isso um maior grau de detalhamento se faz necessário. O ICS-Bagging é baseado em uma inicialização iterativa para formar o conjunto de classificadores. Cada iteração gera um conjunto de classificadores e seleciona o melhor classificador deste conjunto. A amostragem de inicialização usa uma probabilidade de amostragem a partir de cada classe, sendo esta probabilidade derivada a partir da taxa de erro da classe. O algoritmo abaixo descreve o funcionamento do ICS-Bagging.
\begin{algorithm}[H]

\caption{ICS-Bagging}
\begin{algorithmic}[1]
	\REQUIRE $\mathcal{T}$: conjunto de treinamento.
	\REQUIRE $\mathcal{V}$: conjunto de validação.
    \REQUIRE $N$: tamanho da pool.
    \REQUIRE $K$: número de classificadores a serem adicionados a cada iteração.
    \REQUIRE $\alpha$: parâmetro da função de fitness.
    \REQUIRE \textit{diversity}: métrica de diversidade a ser usada.
    \STATE $\mathcal{P} \gets$ lista vazia de classificadores.
	\STATE Gera o classificador usando uma inicialização aleatória das amostras adicionando-as em $\mathcal{P}$.
    \WHILE {$|\mathcal{P}| < N$}
        \STATE \textit{pesos} $\gets$ $Probabilidade_{classe_i} = 1 - \dfrac{FN_{classe_i}}{\sum\nolimits_{classe_j \in classes} FN_{classe_j}}$.
        \STATE $C$ = $K$ classificadores usando \textit{pesos} para executar a inicialização das amostras.
        \FORALL {classificador $c_i \in C$}
            \STATE Adicione $c_i$ em $\mathcal{P}$.
            \STATE \textit{acc} $\gets AUC(\mathcal{P})$
            \STATE \textit{div} $\gets \text{\textit{diversity}}(\mathcal{P})$
            \STATE $fitness(c_i) \gets \alpha \times acc + (1 - \alpha) \times div$
            \STATE Remova $c_i$ de $\mathcal{P}$.
		\ENDFOR
        \STATE $melhor \gets argmax(fitness, C)$
        \STATE Adicione $C[melhor]$ em $\mathcal{P}$
        \STATE Atualize \textit{pesos}
	\ENDWHILE
	\RETURN $\mathcal{P}$
\end{algorithmic}
\label{alg:abag}
\end{algorithm}

Abaixo, uma explicação formulada de maneira textualmente mais livre:

\par \textbf{Pré-processamento: } Antes de gerar os classificadores, alguma técnica de pré-processamento pode ser aplicada ao conjunto de treinamento. Este pré-processamento consiste em remover ruídos, dados redundantes ou gerar novos dados. No entanto, o algoritmo ICS-Bagging não tem essa etapa.

\textbf{Gerar K classificadores: } Este passo gera K classificadores usando uma amostra de inicialização (com reposição). No primeiro passo os pesos são os mesmos para todas as classes; depois do primeiro passo os peses são atualizados para priorizar a classe que possui maior taxa de erro. A motivação de se usar pesos para guiar o processo de inicialização é focar nos exemplos que são mais difíceis de serem classificados. E a motivação de se utilizar K \textgreater 1 classificadores para que se aumente a região de busca, aumentando a probabilidade de se achar um classificador que consideravelmente aumente a diversidade e a acurácia na classificação.

\par \textbf{Adicionar o melhor classificador na \textit{pool}:} Para cada um dos K classificadores gerados os seguintes passos são executados para achar o melhor classificador. $C$ é a lista dos K classificadores gerados, $\mathcal{V}$ é o conjunto de validação (neste trabalho foi utilizado o conjunto de treinamento como sendo o conjunto de validação) e $\mathcal{P}$ é a \textit{pool} atual de classificadores. 

\par Para todos os classificadores em $C$, o classificador é adicionado à \textit{pool} (Linha 4), e então o \textit{fitness} da \textit{pool} (Linha 5) é calculado pelo fórmula abaixo:

\begin{equation}
\text{\textit{fitness}} = \alpha \times \text{\textit{ACC}} + (1 - \alpha) \times \text{\textit{DIV}}
\label{eq:fitness}
 \end{equation}
 
\noindent onde \textit{ACC} é a acurácia de classificação da \textit{pool}, \textit{DIV} é a métrica de diversidade, e $\alpha$ é o parâmetro que regula a proporção que a diversidade ou a acurácia da classificação possui na função de \textit{fitness}, este valor varia entre 0.01 e 0.99.

Se a \textit{pool}  alcança o maior \textit{fitness} com esse classificador, então o índice desse classificador é salvo em \textit{melhor}$_{index}$ (Linha 6 - 9). O classificador é removido da \textit{pool} (Linha 10) e o processo começa novamente utilizando outro classificador até que o melhor classificador seja retornado (Linha 12).

Para a classificação de uma amostra de teste, qualquer regra de combinação pode ser utilizada. Para este trabalho foi utilizado a regra da maioria dos votos \cite{kuncheva:2004} para combinar as saídas dos classificadores na \textit{pool}.

Quaisquer métricas de classificação ou de diversidade podem ser usadas na Equação \ref{eq:fitness}, mas ambas precisam ser normalizadas (entre 0 1 ). Neste trabalho foi utilizado a área sobre a curva ROC - AUC, e como medida de diversidade foi utilizada a Entropia $E$ \cite{diversity:2003}, a métrica tal e a métrica tal... %TODO colocar quais métricas serão usadas

%The Entropy Measure $E$ is a non-pairwise diversity measure that has it's highest value when half classifiers correctly classify a pattern and the other half doesn't. If all classifiers have the same agree on a classification, the %ensemble is not considered diverse. The Entropy Measure $E$ is described as

    \begin{equation}
    \text{\textit{E}} = \dfrac{1}{N} \sum_{j=1}^{N} \dfrac{1}{(L - \lceil\frac{L}{2}\rceil)} \text{\textit{min}}\{l(z_j), L - l(z_j)\}
    \label{eq:entropy}
    \end{equation}

%The motivation for adding only one of the $K$ generated classifiers is because the accuracy of each class might change when the best classifier is inserted in the pool, which means, the pool now has different samples to prioritize in %order to increase classification accuracy and diversity.

% TODO colocar algum tipo de motivação de se variar o K


\textbf{$|$pool$|$ = N}: Se a \textit{pool} já contém o número desejado de classificadores, então a \textit{pool} é retornada.I

\textbf{Atualiza o peso de cada classe}: Como a precisão de cada classe pode mudar depois que um novo classificador for inserido na \text{pool}, os pesos precisam ser atualizados utilizando a  Equação \ref{eq:weight},

    \begin{equation}
    peso_{classe} =  1.0 - \dfrac{acuracia_{classe}}{\sum\nolimits_{c \in classes} acuracia_{c}}
    \label{eq:weight}
    \end{equation}

\noindent onde $peso_{classe}$ é o peso da classe, $acurácia_{classe}$ é a taxa de acerto da classe, e $\sum\nolimits_{c \in classes} acurácia_{c}$ é a soma da taxa de acerto de todas as classes.

E como foi mencionado anteriormente, a motivação de se atualizar os pesos é aumentar a probabilidade de treinar um novo classificador $K$ com amostras da classe com uma baixa taxa de acerto na \textit{pool}.
%\item 

\textbf{Retorne a \textit{pool}}: A \textit{pool} final de classificadores é retornada.
%\end{enumerate}

Um esquema do fluxo de funcionamento do algoritmo ICS-Bagging pode ser visto na figura \ref{fig:icsbaggingesquema}.

\begin{figure}[H]
\center
\includegraphics[scale=0.45]{imagens/icsbaggingesquema-2.png}
\caption{Arquitetura do ICS-Bagging. Onde L é o conjunto final de classificadores.}
\label{fig:icsbaggingesquema}
\end{figure}


