\chapter{Combinação de Classificadores}

Neste capítulo, será mostrado um conceito e análise de combinação de classificadores e os principais algoritmos desta área, Bagging e Boosting. Cada seção aborda os conceitos básicos do tema e de cada algoritmo, o seu pseudo-código e suas características principais, bem como as variações mais conhecidas. Ao final, de maneira mais detalhada, será analisado o algoritmo ICS-Bagging com foco nas possíveis métricas de diversidade que este algoritmo pode usar bem como uma análise a respeito de métricas de diversidade. 

\section{Selecionar Classificadores}

Antes de se combinar classificadores de fato é preciso selecioná-los. Em uma análise menos acurada, parece ser algo intuitivo. No entanto, neste assunto reside alguns aspectos importantes que servem de base para o entendimento dos algoritmos que serão tratados nas próximas seções. 
A ideia base de se selecionar classificadores é de que existe uma espécie de "oráculo" que pode selecionar o melhor classificador para uma dada entrada \textbf{x}. A decisão deste melhor classificador é tida como sendo a decisão do conjunto de classificadores. 
A ideia de usar diferentes classificadores para diferentes entradas foi primeiramente sugerida por Dasarathy e Sheela em 1978 [ref 118]. Os autores combinaram um classificador linear e o \textit{K-Nearest Neighbor}. A combinação dos classificadores identifica o domínio de conflito dentro do espaço de características e utiliza o \textit{K-Nearest Neighbor} neste domínio, enquanto que o classificador linear é utilizado nos demais domínios. E no ano de 1981 Rastrigin e Erenstein [ref 119] propuseram uma metodologia de seleção de classificadores como é conhecida atualmente. 
Posteriormente, o interesse em seleção de classificadores foi impulsionado pela publicação de Woods et al. [ref 120]. Os autores introduziram o termo \textit{seleção dinâmica de classificadores} para denotar o processo de escolher um membro do conjunto de classificadores para tomar uma decisão baseada na entrada \textbf{x}.
Partindo desta proposta, para se construir a seleção do conjunto de classificadores, algumas perguntas precisam ser feitas:
\begin{itemize} \item Como construir os classificadores individuais? \item Como avaliar a competência de cada classificador dado uma entrada \textbf{x}? \item Uma vez que a competência de um classificador foi avaliada, qual estratégia deverá ser utilizada?  \end{itemize}

\subsection{Regras de Combinação} 

Como será visto adiante, alguns algoritmos de combinação de classificadores possuem regras de combinação embutidas no seu próprio algoritmo. Por exemplo, o algoritmo Bagging utiliza uma maioria dos votos simples, já no AdaBoost é utilizado uma maioria dos votos com pesos. No entanto, um conjunto de classificadores pode ser treinado simplesmente usando um subconjunto do conjunto de treinamento, diferentes parâmetros dos classificadores ou até mesmo diferentes subconjuntos de características. 

Os classificadores podem ser combinados usando uma ou mais regras de combinação. Algumas dessas regras de combinação operam apenas nos \textit{labels} das classes, outras possuem mecanismos mais sofisticados. Mas, de forma prática, pode-se dividir as regras de combinação entre métodos baseados em votos, métodos algébricos e outras formas de combinação. 

A regra baseada em votos, é bastante simples, e como o próprio nome já diz, cada classificador dá um voto ao classificar uma nova instância. Duas formas de votos são muito conhecidas, o voto da maioria e o voto com pesos. No primeiro caso, cada classificador, ao receber uma nova instância a ser classificada, provê seu voto como sendo o resultado da sua classificação. A classe que foi apontada como a maioria dos votos é a classe na qual a instância será classificada. Analogamente, nos votos com pesos, alguns classificadores ou até mesmo instância de treinamento, possuem um peso maior. De forma que a votação se dá da mesma forma, apenas algumas instâncias ou classificadores detêm um peso maior no seu voto.

Outras regras são conhecidas na literatura, porém não é o objetivo de estudo deste trabalho. Estes incluem \textit{Borda count},\textit{behavior knowledge space} e \textit{decision templates} como rol apenas exemplificativo, já que a lista não se exaure dentro destes. 

\subsection{Diversidade}

O sucesso de um sistema que combina classificadores reside na diversidade dos seus membros. De forma que se todos os classificadores fornecessem a mesma saída, nada estaria sendo feito, e nenhum erro poderia ser corrigido. Por isso cada classificador individual precisa de diferente, de certa forma, dos demais classificadores. Isso leva ao raciocínio de que erros cometidos por alguns classificadores são compensados por acertos dos outros classificadores, assim obtêm-se uma diminuição do erro global. Outra forma de se obter ganho nessa abordagem, é que alguns classificadores são bons em determinados domínios do problemas, e a diversidade destes classificadores faz com que uma maior região do problema possa ser resolvida de uma forma maior acurada.  

\subsection{Pontos Fracos}

A contrapartida do aumento da taxa de acerto ao se combinar classificadores ocorre um principalmente três pontos: é necessário mais armazenamento, mais capacidade computacional e a complexidade de entendimento aumenta. O primeiro ponto fraco, necessidade de mais armazenamento, é consequência direta de que vários classificadores e não apenas um precisa ser armazenado após a fase de treinamento. O segundo problema decorre naturalmente do aumento da capacidade computacional requerida dado que vários classificadores precisam ser processados e não apenas um. O último, complexidade no entendimento, envolve uma maior dificuldade para se compreender de forma intuitiva ou até mesmo trivial o que realmente incorpora melhores resultados nos algoritmos.

\section{Bagging}
\textit{Bagging} é um algoritmo \cite{bagging:1996} de combinação de classificadores que foi desenvolvido com o intuito de melhorar a acurácia na tarefa de classificação. O principal conceito deste algoritmo é o \textit{bootstrap aggregation}, na qual o conjunto de treinamento para cada classificador é construído a partir de uma amostra escolhida aleatoriamente do conjunto de treinamento. Os classificadores são então combinados e ao se apresentar uma nova instância, cada classificador fornece como resultado a classe na qual essa nova instância pertence. Normalmente, a classe que obteve mais votos, é dita como sendo a classe desta instância. 


\begin{algorithm}
\caption{Bagging}
\label{alg:bagging}
\begin{algorithmic}
\STATE Dado o conjunto de treinamento $T$
\FORALL {t = 1, ..., n}
		\STATE Para cada amostra $S$ do conjunto de treinamento $T$ selecione \textit{m} exemplos aleatórios com reposição
		\STATE Considere $ht$ o resultado do classificador $t$ para o conjunto de treinamento $S$
\ENDFOR
\STATE $Resultado \gets$ a maioria dos votos de $(h1(x), ..., hT(x))$
\RETURN $Resultado$
\end{algorithmic}
\end{algorithm}

Assim, como pode ser observado melhor acima, para cada \textit{n} interações uma réplica do conjunto de treinamento é criada. E um classificador é treinado com essa réplica, este processo continua até uma quantidade de interações desejada. Após uma quantidade de interações previamente escolhida, uma combinação de classificadores é gerada e a maioria dos votos desses classificadores determina a classe de uma nova instância.

\section{Boosting}
 \textit{Boosting} é um método geral para melhorar a precisão de uma classificação. O objetivo deste método é produzir um classificador forte a partir de um conjunto de vários classificadores fracos. Um classificador é dito fraco quando este tem uma taxa de acerto boa, mas somente para uma porção da base de dados. Por isso a ideia de combinar vários classificadores ditos fracos para formar uma combinação de classificadores que tem uma precisão melhor. Um analogia favorável ao entendimento é que um classificador fraco é um bom classificador para um determinado domínio, e a junção de vários classificadores fracos forma uma combinação de classificadores forte.
 
 %ALTERAR ESTE ALGORITMO PARA BOOSTING 
 \begin{algorithm}
\caption{Boosting}
\label{alg:boosting}
\begin{algorithmic}
\STATE Dado o conjunto de treinamento $T$
\FORALL {t = 1, ..., n}
		\STATE Para cada amostra $S$ do conjunto de treinamento $T$ selecione \textit{m} exemplos aleatórios com reposição
		\STATE Considere $ht$ o resultado do classificador $t$ para o conjunto de treinamento $S$
\ENDFOR
\STATE $Resultado \gets$ a maioria dos votos de $(h1(x), ..., hT(x))$
\RETURN $Resultado$
\end{algorithmic}
\end{algorithm}

O método \textit{boosting} treina iterativamente cada classificador atribuindo a cada instância um peso após este treinamento. Os pesos de cada instância são acrescidos quando esta instância é classificada incorretamente e analogamente este peso é decrementado quando classificado corretamente. Isto faz com que cada classificador foque nos exemplos mais difíceis. Depois que a cominação de classificadores for gerada, uma regra de escolha é usada,  maioria dos votos por exemplo. 

\subsection{AdaBoost}
Um dos mais famosos algoritmos da família \textit{boosting} é o \textit{AdaBoost}, este algoritmo foi a primeira abordagem prática do \textit{Boosting} e hoje é apontando como um dos top dez dos algoritmos de aprendizagem de máquina[94 review] . Este algoritmo utiliza todo o conjunto de dados para treinar cada classificador, mas a cada iteração é dado um foco maior a instâncias difíceis de classificar. O objetivo é classificar corretamente na próxima iteração uma instância que foi classificada de forma errada na iteração atual. Com isso, é dado um foco maior em instâncias que são difíceis de se classificar.
Depois de cada iteração, os pesos das instâncias que foram classificadas de forma errada são aumentando; e em contraste, os pesos das instâncias que foram classificadas corretamente são decrementados. Além disso outro peso é atribuído a cada classificador individual, dependendo da sua taxa de acerto na fase de treinamento.
Finalmente, quando uma nova instância é apresentada, cada classificador dá um voto, e a classe selecionada foi a que obteve a maioria dos votos. Lembrando que os classificadores possuem pesos diferentes nas votações. O algoritmo pode ser conferido abaixo.

% TODO - ver outro código ou traduzir e rever
\begin{algorithm}[h]
\caption{AdaBoost}
\label{alg:1}
\begin{algorithmic}[1]
\STATE \textbf{ENTRADA:}
\item Conjunto de Treinamento: $\mathcal{D} = \{(x_i, y_i), i=1, \ldots, N
\}$, onde $x_i \in \mathbf{R}^d$ e $y_i \in \{-1, +1\}$.
\item O número de amostras em cada iteração: $m$
\item Classificador Fraco: $\mathcal{L}$ that automatically learns a binary classifier $h(x): \mathbf{R}^d \mapsto \{-1, +1\}$
de um conjunto de treinamento.
\item O número de iterações: $T$
\STATE \textbf{SAÍDA:}
\item O Classificador Final: $H(x) = sign\left(\sum_{t=1}^T \alpha_t h_t(x) \right)$

\STATE \textbf{Algorithm}

\STATE Inicialize a distribuição $D_0(i) = 1/N, i=1, \ldots, N$

\FOR{$t = 1$ até $T$}

\STATE Sample $m$ examples with replacement from $\mathcal{D}$
de acordo com a distribuição $D_{t-1}(i)$.

\STATE Treine o classificador $h_t(x)$ usando os exemplos da amostra

\STATE Compute a taxa de erro $\varepsilon_t = \sum_{i=1}^N
D_{t-1}(i) I(h_t(x_i) \neq y_i)$ onde $I(z)$ outputs $1$ quando $z$
é verdadeiro e zero caso contrário.

\STATE Saia do loop se $\varepsilon > 0.5$.

\STATE Compute o peso como $\alpha_t$ em
\[\alpha_t = \frac{1}{2}\ln\left(\frac{1-\varepsilon_t}{\varepsilon_t}\right) \]

\STATE Atualize a distribuição em as
\[ D_t(i) = \frac{1}{Z_t} D_{t-1}(i)\exp(\alpha_tI(y_i \neq h_t(x_i))\]
where $Z_t = \sum_{i=1}^N D_{t-1}(i)\exp(\alpha_tI(y_i \neq
h_t(x_i))$.

\ENDFOR

\STATE Construct the final classifier $H(x) = sign(\sum_{t=1}^T
\alpha_t h_t(x))$.

\end{algorithmic}
\end{algorithm}

% FIM DO TODO


\section{ICS-Bagging}
O algoritmo ICS-Bagging,  acrônimo de \textit{Iteractive Classifier Selection Baggin},  é o ponto central e objetivo de estudo deste trabalho. Por isso um maior grau de detalhamento se faz necessário. O ICS-Bagging é baseado em uma inicialização iterativa para formar o conjunto de classificadores. Cada iteração gera um conjunto de classificadores e seleciona o melhor classificador deste conjunto. A amostragem de inicialização usa uma probabilidade de amostragem a partir de cada classe, sendo esta probabilidade derivada a partir da taxa de erro da classe. O algoritmo abaixo descreve o funcionamento do ICS-Bagging.
\begin{algorithm}[H]
%\begin{algorithm*}
%\begin{figure*}
\caption{ICS-Bagging}
\begin{algorithmic}[1]
	\REQUIRE $\mathcal{T}$: conjunto de treinamento.
	\REQUIRE $\mathcal{V}$: conjunto de validação.
    \REQUIRE $N$: tamanho da pool.
    \REQUIRE $K$: número de classificadores a serem adicionados a cada iteração.
    \REQUIRE $\alpha$: parâmetro da função de fitness.
    \REQUIRE \textit{diversity}: métrica de diversidade a ser usada.
    \STATE $\mathcal{P} \gets$ lista vazia de classificadores.
	\STATE Gera o classificador usando uma inicialização aleatória das amostras adicionando-as em $\mathcal{P}$.
    \WHILE {$|\mathcal{P}| < N$}
        \STATE \textit{pesos} $\gets$ $Probabilidade_{classe_i} = 1 - \dfrac{FN_{classe_i}}{\sum\nolimits_{classe_j \in classes} FN_{classe_j}}$.
        \STATE $C$ = $K$ classificadores usando \textit{pesos} para executar a inicialização das amostras.
        \FORALL {classificador $c_i \in C$}
            \STATE Adicione $c_i$ em $\mathcal{P}$.
            \STATE \textit{acc} $\gets AUC(\mathcal{P})$
            \STATE \textit{div} $\gets \text{\textit{diversity}}(\mathcal{P})$
            \STATE $fitness(c_i) \gets \alpha \times acc + (1 - \alpha) \times div$
            \STATE Remova $c_i$ de $\mathcal{P}$.
		\ENDFOR
        \STATE $melhor \gets argmax(fitness, C)$
        \STATE Adicione $C[melhor]$ em $\mathcal{P}$
        \STATE Atualize \textit{pesos}
	\ENDWHILE
	\RETURN $\mathcal{P}$
\end{algorithmic}
\label{alg:abag}
\end{algorithm}

Abaixo, uma explicação formulada de maneira textualmente mais livre:

\par \textbf{Pré-processamento: } Antes de gerar os classificadores, alguma técnica de pré-processamento pode ser aplicada ao conjunto de treinamento. Este pré-processamento consiste em remover ruídos, dados redundantes ou gerar novos dados. No entanto, o algoritmo ICS-Bagging não tem essa etapa.

\textbf{Gerar K classificadores: } Este passo gera K classificadores usando uma amostra de inicialização (com reposição). No primeiro passo os pesos são os mesmos para todas as classes; depois do primeiro passo os peses são atualizados para priorizar a classe que possui maior taxa de erro. A motivação de se usar pesos para guiar o processo de inicialização é focar nos exemplos que são mais difíceis de serem classificados. E a motivação de se utilizar K \textgreater 1 classificadores para que se aumente a região de busca, aumentando a probabilidade de se achar um classificador que consideravelmente aumente a diversidade e a acurácia na classificação.

\par \textbf{Adicionar o melhor classificador na \textit{pool}:} Para cada um dos K classificadores gerados os seguintes passos são executados para achar o melhor classificador. $C$ é a lista dos K classificadores gerados, $\mathcal{V}$ é o conjunto de validação (neste trabalho foi utilizado o conjunto de treinamento como sendo o conjunto de validação) e $\mathcal{P}$ é a \textit{pool} atual de classificadores. 

\par Para todos os classificadores em $C$, o classificador é adicionado à \textit{pool} (Linha 4), e então o \textit{fitness} da \textit{pool} (Linha 5) é calculado pelo fórmula abaixo:

\begin{equation}
\text{\textit{fitness}} = \alpha \times \text{\textit{ACC}} + (1 - \alpha) \times \text{\textit{DIV}}
\label{eq:fitness}
 \end{equation}
 
\noindent onde \textit{ACC} é a acurácia de classificação da \textit{pool}, \textit{DIV} é a métrica de diversidade, e $\alpha$ é o parâmetro que regula a proporção que a diversidade ou a acurácia da classificação possui na função de \textit{fitness}, este valor varia entre 0.01 e 0.99.

Se a \textit{pool}  alcança o maior \textit{fitness} com esse classificador, então o índice desse classificador é salvo em \textit{melhor}$_{index}$ (Linha 6 - 9). O classificador é removido da \textit{pool} (Linha 10) e o processo começa novamente utilizando outro classificador até que o melhor classificador seja retornado (Linha 12).

Para a classificação de uma amostra de teste, qualquer regra de combinação pode ser utilizada. Para este trabalho foi utilizado a regra da maioria dos votos \cite{kuncheva:2004} para combinar as saídas dos classificadores na \textit{pool}.

Quaisquer métricas de classificação ou de diversidade podem ser usadas na Equação \ref{eq:fitness}, mas ambas precisam ser normalizadas (entre 0 1 ). Neste trabalho foi utilizado a área sobre a curva ROC - AUC, e como medida de diversidade foi utilizada a Entropia $E$ \cite{diversity:2003}, a métrica tal e a métrica tal... %TODO colocar quais métricas serão usadas

%The Entropy Measure $E$ is a non-pairwise diversity measure that has it's highest value when half classifiers correctly classify a pattern and the other half doesn't. If all classifiers have the same agree on a classification, the %ensemble is not considered diverse. The Entropy Measure $E$ is described as

    \begin{equation}
    \text{\textit{E}} = \dfrac{1}{N} \sum_{j=1}^{N} \dfrac{1}{(L - \lceil\frac{L}{2}\rceil)} \text{\textit{min}}\{l(z_j), L - l(z_j)\}
    \label{eq:entropy}
    \end{equation}

%The motivation for adding only one of the $K$ generated classifiers is because the accuracy of each class might change when the best classifier is inserted in the pool, which means, the pool now has different samples to prioritize in %order to increase classification accuracy and diversity.

% TODO colocar algum tipo de motivação de se variar o K


\textbf{$|$pool$|$ = N}: Se a \textit{pool} já contém o número desejado de classificadores, então a \textit{pool} é retornada.I

\textbf{Atualiza o peso de cada classe}: Como a precisão de cada classe pode mudar depois que um novo classificador for inserido na \text{pool}, os pesos precisam ser atualizados utilizando a  Equação \ref{eq:weight},

    \begin{equation}
    peso_{classe} =  1.0 - \dfrac{acuracia_{classe}}{\sum\nolimits_{c \in classes} acuracia_{c}}
    \label{eq:weight}
    \end{equation}

\noindent onde $peso_{classe}$ é o peso da classe, $acurácia_{classe}$ é a taxa de acerto da classe, e $\sum\nolimits_{c \in classes} acurácia_{c}$ é a soma da taxa de acerto de todas as classes.

E como foi mencionado anteriormente, a motivação de se atualizar os pesos é aumentar a probabilidade de treinar um novo classificador $K$ com amostras da classe com uma baixa taxa de acerto na \textit{pool}.
%\item 

\textbf{Retorne a \textit{pool}}: A \textit{pool} final de classificadores é retornada.
%\end{enumerate}

