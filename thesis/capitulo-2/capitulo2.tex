\chapter{Combinação de Classificadores}
Neste capítulo, será mostrado os principais algoritmos de combinação de classificadores, Bagging e Boosting. Cada seção aborda os conceitos básicos de cada algoritmo, o seu pseudo-código e suas características principais, bem como as variações mais conhecidas. Ao final, de maneira mais detalhada, será analisado o algoritmo ICS-Bagging com foco nas possíveis métricas de diversidade que este algoritmo pode usar. 

\section{Bagging}
\textit{Bagging} é um algoritmo \cite{bagging:1996} de combinação de classificadores que foi desenvolvido com o intuito de melhorar a acurácia na tarefa de classificação. O principal conceito deste algoritmo é o \textit{bootstrap aggregation}, na qual o conjunto de treinamento para cada classificador é construído a partir de uma amostra escolhida aleatoriamente do conjunto de treinamento. Os classificadores são então combinados e ao se apresentar uma nova instância, cada classificador fornece como resultado a classe na qual essa nova instância pertence. Normalmente, a classe que obteve mais votos, é dita como sendo a classe desta instância. 


\begin{algorithm}
\caption{Bagging}
\label{alg:bagging}
\begin{algorithmic}
\STATE Dado o conjunto de treinamento $T$
\FORALL {t = 1, ..., n}
		\STATE Para cada amostra $S$ do conjunto de treinamento $T$ selecione \textit{m} exemplos aleatórios com reposição
		\STATE Considere $ht$ o resultado do classificador $t$ para o conjunto de treinamento $S$
\ENDFOR
\STATE $Resultado \gets$ a maioria dos votos de $(h1(x), ..., hT(x))$
\RETURN $Resultado$
\end{algorithmic}
\end{algorithm}

Assim, como pode ser observado melhor acima, para cada \textit{n} interações uma réplica do conjunto de treinamento é criada. E um classificador é treinado com essa réplica, este processo continua até uma quantidade de interações desejada. Após uma quantidade de interações previamente escolhida, uma combinação de classificadores é gerada e a maioria dos votos desses classificadores determina a classe de uma nova instância.

\section{Boosting}
 \textit{Boosting} é um método geral para melhorar a precisão de uma classificação. O objetivo deste método é produzir um classificador forte a partir de um conjunto de vários classificadores fracos. Um classificador é dito fraco quando este tem uma taxa de acerto boa, mas somente para uma porção da base de dados. Por isso a ideia de combinar vários classificadores ditos fracos para formar uma combinação de classificadores que tem uma precisão melhor. Um analogia favorável ao entendimento é que um classificador fraco é um bom classificador para um determinado domínio, e a junção de vários classificadores fracos forma uma combinação de classificadores forte.
 
 %ALTERAR ESTE ALGORITMO PARA BOOSTING 
 \begin{algorithm}
\caption{Boosting}
\label{alg:boosting}
\begin{algorithmic}
\STATE Dado o conjunto de treinamento $T$
\FORALL {t = 1, ..., n}
		\STATE Para cada amostra $S$ do conjunto de treinamento $T$ selecione \textit{m} exemplos aleatórios com reposição
		\STATE Considere $ht$ o resultado do classificador $t$ para o conjunto de treinamento $S$
\ENDFOR
\STATE $Resultado \gets$ a maioria dos votos de $(h1(x), ..., hT(x))$
\RETURN $Resultado$
\end{algorithmic}
\end{algorithm}

O método \textit{boosting} treina iterativamente cada classificador atribuindo a cada instância um peso após este treinamento. Os pesos de cada instância são acrescidos quando esta instância é classificada incorretamente e analogamente este peso é decrementado quando classificado corretamente. Isto faz com que cada classificador foque nos exemplos mais difíceis. Depois que a cominação de classificadores for gerada, uma regra de escolha é usada,  maioria dos votos por exemplo. 

\subsection{AdaBoost}
Um dos mais famosos algoritmos da família \textit{boosting} é o \textit{AdaBoost}, este algoritmo foi a primeira abordagem prática do \textit{Boosting} e hoje é apontando como um dos top dez dos algoritmos de aprendizagem de máquina[94 review] . Este algoritmo utiliza todo o conjunto de dados para treinar cada classificador, mas a cada iteração é dado um foco maior a instâncias difíceis de classificar. O objetivo é classificar corretamente na próxima iteração uma instância que foi classificada de forma errada na iteração atual. Com isso, é dado um foco maior em instâncias que são difíceis de se classificar.
Depois de cada iteração, os pesos das instâncias que foram classificadas de forma errada são aumentando; e em contraste, os pesos das instâncias que foram classificadas corretamente são decrementados. Além disso outro peso é atribuído a cada classificador individual, dependendo da sua taxa de acerto na fase de treinamento.
Finalmente, quando uma nova instância é apresentada, cada classificador dá um voto, e a classe selecionada foi a que obteve a maioria dos votos. Lembrando que os classificadores possuem pesos diferentes nas votações. O algoritmo pode ser conferido abaixo.

% TODO - ver outro código ou traduzir e rever
\begin{algorithm}[h]
\caption{AdaBoost}
\label{alg:1}
\begin{algorithmic}[1]
\STATE \textbf{ENTRADA:}
\item Conjunto de Treinamento: $\mathcal{D} = \{(x_i, y_i), i=1, \ldots, N
\}$, onde $x_i \in \mathbf{R}^d$ e $y_i \in \{-1, +1\}$.
\item O número de amostras em cada iteração: $m$
\item Classificador Fraco: $\mathcal{L}$ that automatically learns a binary classifier $h(x): \mathbf{R}^d \mapsto \{-1, +1\}$
de um conjunto de treinamento.
\item O número de iterações: $T$
\STATE \textbf{SAÍDA:}
\item O Classificador Final: $H(x) = sign\left(\sum_{t=1}^T \alpha_t h_t(x) \right)$

\STATE \textbf{Algorithm}

\STATE Inicialize a distribuição $D_0(i) = 1/N, i=1, \ldots, N$

\FOR{$t = 1$ até $T$}

\STATE Sample $m$ examples with replacement from $\mathcal{D}$
de acordo com a distribuição $D_{t-1}(i)$.

\STATE Treine o classificador $h_t(x)$ usando os exemplos da amostra

\STATE Compute a taxa de erro $\varepsilon_t = \sum_{i=1}^N
D_{t-1}(i) I(h_t(x_i) \neq y_i)$ onde $I(z)$ outputs $1$ quando $z$
é verdadeiro e zero caso contrário.

\STATE Saia do loop se $\varepsilon > 0.5$.

\STATE Compute o peso como $\alpha_t$ em
\[\alpha_t = \frac{1}{2}\ln\left(\frac{1-\varepsilon_t}{\varepsilon_t}\right) \]

\STATE Atualize a distribuição em as
\[ D_t(i) = \frac{1}{Z_t} D_{t-1}(i)\exp(\alpha_tI(y_i \neq h_t(x_i))\]
where $Z_t = \sum_{i=1}^N D_{t-1}(i)\exp(\alpha_tI(y_i \neq
h_t(x_i))$.

\ENDFOR

\STATE Construct the final classifier $H(x) = sign(\sum_{t=1}^T
\alpha_t h_t(x))$.

\end{algorithmic}
\end{algorithm}

% FIM DO TODO


\section{ICS-Bagging}
O algoritmo ICS-Bagging,  acrônimo de \textit{Iteractive Classifier Selection Baggin},  é o ponto central e objetivo de estudo deste trabalho. Por isso um maior grau de detalhamento se faz necessário. O ICS-Bagging é baseado em uma inicialização iterativa para formar o conjunto de classificadores. Cada iteração gera um conjunto de classificadores e seleciona o melhor classificador deste conjunto. A amostragem de inicialização usa uma probabilidade de amostragem a partir de cada classe, sendo esta probabilidade derivada a partir da taxa de erro da classe. O algoritmo abaixo descreve o funcionamento do ICS-Bagging.
\begin{algorithm}[H]
%\begin{algorithm*}
%\begin{figure*}
\caption{ICS-Bagging}
\begin{algorithmic}[1]
	\REQUIRE $\mathcal{T}$: conjunto de treinamento.
	\REQUIRE $\mathcal{V}$: conjunto de validação.
    \REQUIRE $N$: tamanho da pool.
    \REQUIRE $K$: número de classificadores a serem adicionados a cada iteração.
    \REQUIRE $\alpha$: parâmetro da função de fitness.
    \REQUIRE \textit{diversity}: métrica de diversidade a ser usada.
    \STATE $\mathcal{P} \gets$ lista vazia de classificadores.
	\STATE Gera o classificador usando uma inicialização aleatória das amostras adicionando-as em $\mathcal{P}$.
    \WHILE {$|\mathcal{P}| < N$}
        \STATE \textit{pesos} $\gets$ $Probabilidade_{classe_i} = 1 - \dfrac{FN_{classe_i}}{\sum\nolimits_{classe_j \in classes} FN_{classe_j}}$.
        \STATE $C$ = $K$ classificadores usando \textit{pesos} para executar a inicialização das amostras.
        \FORALL {classificador $c_i \in C$}
            \STATE Adicione $c_i$ em $\mathcal{P}$.
            \STATE \textit{acc} $\gets AUC(\mathcal{P})$
            \STATE \textit{div} $\gets \text{\textit{diversity}}(\mathcal{P})$
            \STATE $fitness(c_i) \gets \alpha \times acc + (1 - \alpha) \times div$
            \STATE Remova $c_i$ de $\mathcal{P}$.
		\ENDFOR
        \STATE $melhor \gets argmax(fitness, C)$
        \STATE Adicione $C[melhor]$ em $\mathcal{P}$
        \STATE Atualize \textit{pesos}
	\ENDWHILE
	\RETURN $\mathcal{P}$
\end{algorithmic}
\label{alg:abag}
\end{algorithm}

Abaixo, uma explicação formulada de maneira textualmente mais livre:

\par \textbf{Pré-processamento: } Antes de gerar os classificadores, alguma técnica de pré-processamento pode ser aplicada ao conjunto de treinamento. Este pré-processamento consiste em remover ruídos, dados redundantes ou gerar novos dados. No entanto, o algoritmo ICS-Bagging não tem essa etapa.

\textbf{Gerar K classificadores: } Este passo gera K classificadores usando uma amostra de inicialização (com reposição). No primeiro passo os pesos são os mesmos para todas as classes; depois do primeiro passo os peses são atualizados para priorizar a classe que possui maior taxa de erro. A motivação de se usar pesos para guiar o processo de inicialização é focar nos exemplos que são mais difíceis de serem classificados. E a motivação de se utilizar K \textgreater 1 classificadores para que se aumente a região de busca, aumentando a probabilidade de se achar um classificador que consideravelmente aumente a diversidade e a acurácia na classificação.

\par \textbf{Adicionar o melhor classificador na \textit{pool}:} Para cada um dos K classificadores gerados os seguintes passos são executados para achar o melhor classificador. $C$ é a lista dos K classificadores gerados, $\mathcal{V}$ é o conjunto de validação (neste trabalho foi utilizado o conjunto de treinamento como sendo o conjunto de validação) e $\mathcal{P}$ é a \textit{pool} atual de classificadores. 

\par Para todos os classificadores em $C$, o classificador é adicionado à \textit{pool} (Linha 4), e então o \textit{fitness} da \textit{pool} (Linha 5) é calculado pelo fórmula abaixo:

\begin{equation}
\text{\textit{fitness}} = \alpha \times \text{\textit{ACC}} + (1 - \alpha) \times \text{\textit{DIV}}
\label{eq:fitness}
 \end{equation}
 
\noindent onde \textit{ACC} é a acurácia de classificação da \textit{pool}, \textit{DIV} é a métrica de diversidade, e $\alpha$ é o parâmetro que regula a proporção que a diversidade ou a acurácia da classificação possui na função de \textit{fitness}, este valor varia entre 0.01 e 0.99.

Se a \textit{pool}  alcança o maior \textit{fitness} com esse classificador, então o índice desse classificador é salvo em \textit{melhor}$_{index}$ (Linha 6 - 9). O classificador é removido da \textit{pool} (Linha 10) e o processo começa novamente utilizando outro classificador até que o melhor classificador seja retornado (Linha 12).

Para a classificação de uma amostra de teste, qualquer regra de combinação pode ser utilizada. Para este trabalho foi utilizado a regra da maioria dos votos \cite{kuncheva:2004} para combinar as saídas dos classificadores na \textit{pool}.

Quaisquer métricas de classificação ou de diversidade podem ser usadas na Equação \ref{eq:fitness}, mas ambas precisam ser normalizadas (entre 0 1 ). Neste trabalho foi utilizado a área sobre a curva ROC - AUC, e como medida de diversidade foi utilizada a Entropia $E$ \cite{diversity:2003}, a métrica tal e a métrica tal... %TODO colocar quais métricas serão usadas

%The Entropy Measure $E$ is a non-pairwise diversity measure that has it's highest value when half classifiers correctly classify a pattern and the other half doesn't. If all classifiers have the same agree on a classification, the %ensemble is not considered diverse. The Entropy Measure $E$ is described as

    \begin{equation}
    \text{\textit{E}} = \dfrac{1}{N} \sum_{j=1}^{N} \dfrac{1}{(L - \lceil\frac{L}{2}\rceil)} \text{\textit{min}}\{l(z_j), L - l(z_j)\}
    \label{eq:entropy}
    \end{equation}

%The motivation for adding only one of the $K$ generated classifiers is because the accuracy of each class might change when the best classifier is inserted in the pool, which means, the pool now has different samples to prioritize in %order to increase classification accuracy and diversity.

% TODO colocar algum tipo de motivação de se variar o K


\textbf{$|$pool$|$ = N}: Se a \textit{pool} já contém o número desejado de classificadores, então a \textit{pool} é retornada.I

\textbf{Atualiza o peso de cada classe}: Como a precisão de cada classe pode mudar depois que um novo classificador for inserido na \text{pool}, os pesos precisam ser atualizados utilizando a  Equação \ref{eq:weight},

    \begin{equation}
    peso_{classe} =  1.0 - \dfrac{acuracia_{classe}}{\sum\nolimits_{c \in classes} acuracia_{c}}
    \label{eq:weight}
    \end{equation}

\noindent onde $peso_{classe}$ é o peso da classe, $acurácia_{classe}$ é a taxa de acerto da classe, e $\sum\nolimits_{c \in classes} acurácia_{c}$ é a soma da taxa de acerto de todas as classes.

E como foi mencionado anteriormente, a motivação de se atualizar os pesos é aumentar a probabilidade de treinar um novo classificador $K$ com amostras da classe com uma baixa taxa de acerto na \textit{pool}.
%\item 

\textbf{Retorne a \textit{pool}}: A \textit{pool} final de classificadores é retornada.
%\end{enumerate}

